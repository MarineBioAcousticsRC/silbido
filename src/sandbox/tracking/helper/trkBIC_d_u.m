function [bic, one, two] = trkBIC_d_u(Features, Splits, PenaltyWeight, Prior)
% function bic = trkBIC_d_u(Features, Splits, PenaltyWeight)
% Bayesian Information Criteria test for a set of row feature vectors:
% We generate a BIC point for each SplitPoint in the row vector Splits.
%
%	H0 : Features all generated by one source which can be
%		modeled as a multivariate normal distribution.
%	H1 : Features(1:SplitPoint, :) generated by source 1,
%	     Features(SplitPoint+1:end, :) generated by source 2.
%	     We assume both sources can be modeled as normal
%		distributions.
%
% Features is a set row-oriented feature vectors.  Features(1,:) is
% assumed to contain energy and will be removed before performing the
% test.  
%
% Returns the change in BIC value between H0 and H1.
%
% This code is copyrighted 2003-2005 by Marie Roch and Yanliang Cheng.
% e-mail:  marie.roch@ieee.org
%
% Permission is granted to use this code for non-commercial research
% purposes.  Use of this code, or programs derived from this code for
% commercial purposes without the consent of the author is strictly
% prohibited. 

% Nested fn ----------------------------------------
function ll = LogLikelihoodFn(Data)
% Determine likelihood of given row vector data
  [N, d] = size(Data);
  SampleMu = mean(Data);
  SampleVariance = var(Data);
  SamplePrecision = 1 ./ var(Data);
  Determinant = trkDetSymmetric(diag(SampleVariance));
  
  if Adapt
    % adapt mean
    Mu = (Prior.tau .* Prior.mu + N + SampleMu) ./ (Prior.tau + N);
    % adapt variances
    SumSquaredDeviations = (N - 1) * SampleVariance;
    Alpha = Prior.alpha + N / 2;
    Beta = Prior.beta + .5 * SumSquaredDeviations + ...
           Prior.tau * N .* (SampleMu - Prior.mu) .^2 / ...
           (2 * (Prior.tau + N));
    Precision = (Alpha - 1) ./ Beta;
    Variance = 1 ./ Precision;
% $$$     Variance = SampleVariance;
% $$$     Precision = SamplePrecision;
  else
    Mu = SampleMu;
    Variance = SampleVariance;
    Precision = SamplePrecision;
  end
    
  % compute pdfs exploiting diagonal covariance matrix
  Offsets = (Data - Mu(ones(1,N), :)) .^ 2;
  Quadratic = ((Data - Mu(ones(1,N), :)) .^ 2) .* Precision(ones(1,N), :);
  LogQuadratic = -.5 * sum(sum(Quadratic));
  ll = (N/2)*(-d*log(2*pi) - log(prod(Variance))) + LogQuadratic;
  
  
  % $$$   % debugging code for making sure likelihood is correct.
  % $$    % about an order of magnitude slower than the above
  % $$$   ll2 = 0;
  % $$$   const = (2*pi)^(-d/2) / sqrt(trkDetSymmetric(diag(Variance)));
  % $$$   for k=1:N
  % $$$     offset = (Data(k,:) - Mu);
  % $$$     pdf = const * exp( -.5 * offset * diag(Precision) * offset');
  % $$$     ll2 = ll2 + log(pdf);
  % $$$   end
  % $$$   ll = ll2;
end 

% Nested fn ----------------------------------------
function Det = trkDetSymmetric(SymmetricMatrix)
% Find the determinant of a symmetric matrix.
% No check is made to see if the matrix is actually symmetric.
% Rounding errors which result in low magnitude negative determinants
% will be set to zero.

  Det = det(SymmetricMatrix);
  if Det <= 0
    % If the condition number is large, assume accuracy problems
    % and set determinant to near zero.
    if cond(SymmetricMatrix) > 1e4
      Det = NaN;
    else
      warning('Matrix was not positive definite!')
    end
  end
end

% Main fn ----------------------------------------

if nargin < 4
  LowEnergyPct = 0;
end

Adapt = (nargin == 4);

if size(Splits, 1) > 1
  error('Splits must be a row vector')
end

[NAll, Dim] = size(Features);  % Determine dimension of the feature vectors

% The one model hypothesis is the same regardless of the split point
one = LogLikelihoodFn(Features);
one = one(ones(length(Splits), 1));        % same likelihood for each of the split points

idx = 1;
two = zeros(length(Splits), 1);
for SplitPoint = Splits
  aspeaker = LogLikelihoodFn(Features(1:SplitPoint, :));
  bspeaker = LogLikelihoodFn(Features(SplitPoint+1:end, :));
  two(idx) = aspeaker + bspeaker;
  idx = idx + 1;
end


% compute the penalty factor
%
% The number of parameters is dependent upon the number of means
% and the number of covariance parameters.  The covariance matrix
% is diagonal, meaning that there are only Dim covariance parameters.
%
% H0: Dim + Dim    only one distribution
% H1: 2 [ Dim + Dim ]      two distributions
% So penalize by the difference in the number of parameters. 
%       2Dim, when multiplied by .5
penalty = Dim * log(NAll);


LLR = one - two;       % log likelihood ratio

% compute BIC value
bic = LLR - PenaltyWeight * penalty;

end

